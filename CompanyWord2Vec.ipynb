{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the db cursor and get the data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:8: Warning: Row 39634 was cut by GROUP_CONCAT()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000L"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IP = '127.0.0.1'\n",
    "# USER = 'random'\n",
    "# PASS = 'subset'\n",
    "# SCHEMA = 'test'\n",
    "# mysql_con = MySQLdb.connect(IP, USER, PASS, SCHEMA)\n",
    "# cursor = mysql_con.cursor()\n",
    "# cursor.execute(\"\"\" your query \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each company in the data, perform preprocessing. Preprocessing involves removing punctuation and converting to lowercase. Stemming may also be one of the preprocessing steps. Once we have preprocessed, create a dict that stores the words as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company = {}\n",
    "train=[]\n",
    "from nltk import PunktSentenceTokenizer\n",
    "from string import maketrans,translate,punctuation\n",
    "from itertools import chain\n",
    "tknr = PunktSentenceTokenizer()\n",
    "Trans = maketrans(punctuation, ' '*len(punctuation))\n",
    "for row in cursor:\n",
    "#     company[row[0]]=row[1].decode('utf-8','ignore').encode('ascii','ignore')\n",
    "    text = row[1].decode('utf-8','ignore').encode('ascii','ignore')\n",
    "    sentences = tknr.tokenize(text)\n",
    "    toberemoved = [sent for sent in sentences if len(sent.split()) < 5 and row[0].split()[0] not in sent]\n",
    "    sentences = [sent for sent in sentences if sent not in toberemoved]\n",
    "    clean_words = [translate(s.lower(),Trans).split() for s in sentences]\n",
    "    clean_words.append(row[0].replace(\" \",\"_\").lower())\n",
    "#     print clean_words\n",
    "    sentences2=list(chain(*clean_words))\n",
    "    company[row[0]]=sentences2\n",
    "# model = gensim.models.Word2Vec(company, size=200, window=10, min_count=3, workers=cpu_count())\n",
    "# model.save(\"raw_company.wvec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model using the gensim word2vec model. Tutorial here -> https://radimrehurek.com/gensim/models/word2vec.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19992\n"
     ]
    }
   ],
   "source": [
    "print len(company.keys())\n",
    "from multiprocessing import cpu_count\n",
    "model = gensim.models.Word2Vec(company.values(), size=200, window=5, workers=cpu_count())\n",
    "model.save(\"raw_company.wvec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at what words are similar to some other in the data like 'data','manufacture','machine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "[('predictive', 0.5305579304695129), ('databases', 0.5275143980979919), ('files', 0.5204983949661255), ('database', 0.5094608664512634), ('workflows', 0.4916149973869324), ('document', 0.47610676288604736), ('algorithms', 0.4760831594467163), ('documents', 0.4724388122558594), ('analytics', 0.46168333292007446), ('statistical', 0.4612753689289093)]\n",
      "manufacture:\n",
      "[('tooling', 0.6305778622627258), ('manufacturing', 0.599486231803894), ('manufactures', 0.5985087752342224), ('fabrication', 0.5745141506195068), ('prototypes', 0.5728489756584167), ('machinery', 0.5635436177253723), ('fabricate', 0.5566898584365845), ('manufacturer', 0.5438989996910095), ('extrusion', 0.5407882928848267), ('assemblies', 0.5392353534698486)]\n",
      "machine:\n",
      "[('machines', 0.6665853261947632), ('welding', 0.5511606335639954), ('tooling', 0.5496132969856262), ('hydraulic', 0.526026725769043), ('cnc', 0.5219449400901794), ('fluid', 0.5154760479927063), ('moulding', 0.5083382725715637), ('milling', 0.5075554847717285), ('franking', 0.49873730540275574), ('robotic', 0.494067907333374)]\n"
     ]
    }
   ],
   "source": [
    "print \"data\"\n",
    "print model.most_similar('data')\n",
    "print \"manufacture:\"\n",
    "print model.most_similar('manufacture')\n",
    "print \"machine:\"\n",
    "print model.most_similar('machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If n grams needed to be considered\n",
    "def ngrammer2(l,n):\n",
    "    temp = [\" \".join(l[i:i+n]) for i in xrange(0,len(l)) if len(l[i:i+n])==n]\n",
    "    return temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
